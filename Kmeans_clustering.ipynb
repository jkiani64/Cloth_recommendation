{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:21:27.277991Z",
     "start_time": "2019-11-27T23:21:23.817308Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from skimage.color import rgb2lab, lab2rgb, deltaE_cie76\n",
    "import os\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:21:27.446895Z",
     "start_time": "2019-11-27T23:21:27.359723Z"
    }
   },
   "outputs": [],
   "source": [
    "class Get_dominant_colors:\n",
    "    def __init__(self, image_path, size=None):\n",
    "        '''\n",
    "        Size should be an Tuple\n",
    "        '''\n",
    "        self.image_path = image_path\n",
    "        self.size = size\n",
    "\n",
    "    def _get_prepeare_image(self):\n",
    "        image = cv2.imread(self.image_path)\n",
    "        self.image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if not self.size is None:\n",
    "            self.image_RGB = cv2.resize(\n",
    "                self.image_RGB, self.size, interpolation=cv2.INTER_AREA)\n",
    "        # Convert to Lab format\n",
    "        self.image_LAB = self._convert_RGB_LAB()\n",
    "        # Reshape the image\n",
    "        self.modified_image = self._reshape_image()\n",
    "\n",
    "    def _convert_RGB_LAB(self):\n",
    "\n",
    "        return rgb2lab(np.uint8(np.asarray([self.image_RGB])))\n",
    "\n",
    "    def _reshape_image(self):\n",
    "\n",
    "        _shape = self.image_LAB.shape[0] * \\\n",
    "            self.image_LAB.shape[1]*self.image_LAB.shape[2]\n",
    "        return self.image_LAB.reshape(_shape, 3)\n",
    "\n",
    "    @staticmethod\n",
    "    def Lab_2_HEX(color, color_format):\n",
    "        '''\n",
    "        This function returns the hex values of the given color.\n",
    "        The input format should be Lab or RGB\n",
    "        '''\n",
    "        assert color_format in [\n",
    "            'Lab', 'RGB'], 'Color format not in [\"Lab\", \"RGB\"]'\n",
    "        if color_format == 'Lab':\n",
    "            color = color.reshape(1, 1, 3)\n",
    "            color = lab2rgb(color)*255\n",
    "            color = color.reshape(3,)\n",
    "        return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))\n",
    "\n",
    "    @staticmethod\n",
    "    def perform_kmeans(X, n_clusters):\n",
    "        # Instantiate and fit the Kmeans model\n",
    "        clf = KMeans(n_clusters=n_clusters, random_state=1985).fit(X)\n",
    "        return clf\n",
    "\n",
    "    def get_colors(self, number_of_colors, path_to_save=None):\n",
    "        # Getting the image\n",
    "        self._get_prepeare_image()\n",
    "\n",
    "        # perform kmeans\n",
    "        self.clf = Get_dominant_colors.perform_kmeans(\n",
    "            self.modified_image, number_of_colors)\n",
    "\n",
    "        # sort to ensure correct color percentage\n",
    "        self.counts = dict(sorted(Counter(self.clf.labels_).items(),\n",
    "                                  key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "        # We get ordered colors by iterating through the keys\n",
    "        self.ordered_colors = list(np.concatenate(\n",
    "            [self.clf.cluster_centers_[i] for i in self.counts.keys()], axis=0))\n",
    "\n",
    "        self.hex_colors = [Get_dominant_colors.Lab_2_HEX(self.clf.cluster_centers_[i], 'Lab')\n",
    "                           for i in self.counts.keys()]\n",
    "\n",
    "        if not path_to_save is None:\n",
    "            \n",
    "            color_comp = open(path_to_save, 'a+')\n",
    "            \n",
    "            temp = self.ordered_colors\n",
    "            temp.extend(list(self.counts.values()))\n",
    "            color_comp.writelines([\"%.6f \" % i for i in temp])\n",
    "            color_comp.writelines(\"\\n\")\n",
    "\n",
    "    def plot_dominant_colors(self):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.pie(self.counts.values(), labels=self.hex_colors,\n",
    "                colors=self.hex_colors)\n",
    "\n",
    "    def elbow_plot(self, Num_clusters):\n",
    "        self._get_prepeare_image()\n",
    "        Sum_of_squared_distances=[]\n",
    "        K=range(1, Num_clusters + 1)\n",
    "        for k in K:\n",
    "            kmeans_mdl=Get_dominant_colors.perform_kmeans(\n",
    "                self.modified_image, k)\n",
    "            Sum_of_squared_distances.append(kmeans_mdl.inertia_)\n",
    "        plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "        plt.xlabel('k')\n",
    "        plt.ylabel('Sum_of_squared_distances')\n",
    "        plt.title('Elbow Method For Optimal k')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:37:14.519136Z",
     "start_time": "2019-11-26T23:27:07.997558Z"
    }
   },
   "outputs": [],
   "source": [
    "# dir_overal = 'data/venus/women/tops/long_sleeve/final_images/Cropped_images'\n",
    "# img_dir = os.path.join(dir_overal, 'Upper_cloth')\n",
    "# color_map_path = dir_overal + '/color_map_Upper_cloth.txt'\n",
    "# all_images = os.listdir(img_dir)\n",
    "# all_images.remove('.DS_Store')\n",
    "# for img in tqdm(all_images):\n",
    "#     image_path = os.path.join(img_dir, img)\n",
    "#     img_obj = Get_dominant_colors(image_path, (600, 400))\n",
    "#     img_obj.get_colors(3, path_to_save = color_map_path)\n",
    "    \n",
    "# img_file =  dir_overal + '/Upper_cloth_images.txt'\n",
    "\n",
    "# with open(img_file, 'w') as f:\n",
    "#     for img in all_images:\n",
    "#         f.write('%s\\n' % img)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:46:04.135999Z",
     "start_time": "2019-11-26T23:37:14.526419Z"
    }
   },
   "outputs": [],
   "source": [
    "# dir_overal = 'data/venus/women/tops/long_sleeve/final_images/Cropped_images'\n",
    "# img_dir = os.path.join(dir_overal, 'Lower_cloth')\n",
    "# color_map_path = dir_overal + '/color_map_Lower_cloth.txt'\n",
    "# all_images = os.listdir(img_dir)\n",
    "# all_images.remove('.DS_Store')\n",
    "# for img in tqdm(all_images):\n",
    "#     image_path = os.path.join(img_dir, img)\n",
    "#     img_obj = Get_dominant_colors(image_path, (600, 400))\n",
    "#     img_obj.get_colors(3, path_to_save = color_map_path)\n",
    "    \n",
    "# img_file =  dir_overal + '/Lower_cloth_images.txt'\n",
    "\n",
    "# with open(img_file, 'w') as f:\n",
    "#     for img in all_images:\n",
    "#         f.write('%s\\n' % img)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T23:55:26.568848Z",
     "start_time": "2019-11-26T23:46:04.180371Z"
    }
   },
   "outputs": [],
   "source": [
    "# dir_overal = 'data/venus/women/tops/long_sleeve/final_images/Cropped_images'\n",
    "# img_dir = os.path.join(dir_overal, 'Face')\n",
    "# color_map_path = dir_overal + '/color_map_Face.txt'\n",
    "# all_images = os.listdir(img_dir)\n",
    "# all_images.remove('.DS_Store')\n",
    "# for img in tqdm(all_images):\n",
    "#     image_path = os.path.join(img_dir, img)\n",
    "#     img_obj = Get_dominant_colors(image_path, (600, 400))\n",
    "#     img_obj.get_colors(3, path_to_save = color_map_path)\n",
    "    \n",
    "# img_file =  dir_overal + '/Face_images.txt'\n",
    "\n",
    "# with open(img_file, 'w') as f:\n",
    "#     for img in all_images:\n",
    "#         f.write('%s\\n' % img)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:39:57.807482Z",
     "start_time": "2019-11-27T23:39:57.757186Z"
    }
   },
   "outputs": [],
   "source": [
    "class image_clustering:\n",
    "    \"\"\"\n",
    "    It uses Kmeans clustering to group all\n",
    "    the images with the same color composition\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int, optional, default: 50\n",
    "        The number of clusters to form as well as the number of\n",
    "        centroids to generate.\n",
    "    directory : str\n",
    "        the direcotory of all files\n",
    "    product_url_file : str\n",
    "        The name of csv file including the URL of all images\n",
    "    n_colors : int\n",
    "        The number of dominant colors default is 3\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cluster_centers_ : array, [n_clusters, n_features]\n",
    "        Coordinates of cluster centers. If the algorithm stops before fully\n",
    "        converging (see ``tol`` and ``max_iter``), these will not be\n",
    "        consistent with ``labels_``.\n",
    "    labels_ :\n",
    "        Labels of each point\n",
    "    inertia_ : float\n",
    "        Sum of squared distances of samples to their closest cluster center.\n",
    "    n_iter_ : int\n",
    "        Number of iterations run.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, directory, target_color_map, target_color_image, product_url_file,\n",
    "                 face_file=None, n_clusters=50, weight_face=0, n_colors=3):\n",
    "        self.n_colors = n_colors\n",
    "        assert weight_face >= 0 and weight_face <= 1, print(\n",
    "            'The weight assigned to the face should be between 0 and 1')\n",
    "        self.weight_face = weight_face\n",
    "        self.n_clusters = n_clusters\n",
    "        self.target_path = os.path.join(\n",
    "            directory, 'final_images/Cropped_images/' + target_color_map)\n",
    "        \n",
    "        self.target_image_path = os.path.join(\n",
    "            directory, 'final_images/Cropped_images/' + target_color_image)\n",
    "        \n",
    "        if face_file == None:\n",
    "            self.face_path = None\n",
    "        else:\n",
    "            self.face_path = os.path.join(\n",
    "                directory, 'final_images/Cropped_images/' + face_file)\n",
    "\n",
    "        self.csv_path_url = os.path.join(directory, product_url_file)\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Compute k-means clustering.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
    "            Training instances to cluster. It must be noted that the data\n",
    "            will be converted to C ordering, which will cause a memory\n",
    "            copy if the given data is not C-contiguous.\n",
    "        \"\"\"\n",
    "        self.df_target = image_clustering.read_txt_files(\n",
    "            self.target_path)\n",
    "        if not self.face_path is None:\n",
    "            self.df_target = (1-self.weight_face) * self.df_target +\\\n",
    "                self.weight_face * \\\n",
    "                image_clustering.read_txt_files(self.face_path)\n",
    "\n",
    "        # fit the model\n",
    "        self.mdl = image_clustering.fit_kmeans(\n",
    "            self.df_target[list(range(9))], self.n_clusters)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def read_txt_files(file_path):\n",
    "        df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "        freq_cols = [9, 10, 11]\n",
    "        df[12] = df[freq_cols].sum(axis=1)\n",
    "        for i in freq_cols:\n",
    "            df[i] /= df[12]\n",
    "        color_cols = list(range(0, 9))\n",
    "        for i in color_cols:\n",
    "            df[i] *= df[i // 3 + 9]\n",
    "        try:\n",
    "            df.drop(columns=[12], axis=1, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def fit_kmeans(X, k):\n",
    "        mdl = KMeans(n_clusters=k,\n",
    "                     random_state=1985)\n",
    "        mdl.fit(X)\n",
    "        return mdl\n",
    "\n",
    "    def histohram_plot_cluster(self, path_save_hist=None):\n",
    "        if not hasattr(img_cluster, 'mdl'):\n",
    "            raise ValueError('A model should be fitted first!')\n",
    "        plt.hist(self.mdl.labels_, bins=self.n_clusters)\n",
    "        plt.title('Histogram of Color Comp')\n",
    "        plt.xlabel('Comp')\n",
    "        plt.ylabel('Frequency')\n",
    "        if not path_save_hist is None:\n",
    "            plt.savefig(path_save_hist)\n",
    "\n",
    "    def predict(self, image_path_test, face_path_test=None, num_choice=5):\n",
    "        \"\"\"\n",
    "        Predict the closest image to the test image\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_path_test: a path of the test image\n",
    "        num_choice: the number of desired choices\n",
    "        Returns\n",
    "        -------\n",
    "        labels: array, shape[n_samples, ]\n",
    "            Index of the cluster each sample belongs to.\n",
    "        \"\"\"\n",
    "        img_colors = image_clustering.normalize_image_colors(image_path_test, self.n_colors)\n",
    "        if not self.face_path is None:\n",
    "            temp_face = image_clustering.normalize_image_colors(\n",
    "                face_path_test, self.n_colors)\n",
    "            img_colors = temp_face * self.weight_face + \\\n",
    "                (1 - self.weight_face) * img_colors\n",
    "\n",
    "        # Predict cluster number for the test image\n",
    "        test_label = self.mdl.predict(img_colors)\n",
    "\n",
    "        # Finding the index of neighbors in the same cluster\n",
    "        neighbor_images_idx = np.where(\n",
    "            img_cluster.mdl.labels_ == test_label[0])\n",
    "\n",
    "        # Read the name of all lower clothes images\n",
    "        df_names = pd.read_csv(self.target_image_path, header=None)\n",
    "\n",
    "        # Find the closest images to the target image\n",
    "        ranked_neighbors_diff = image_clustering.Lab_color(\n",
    "            img_colors, neighbor_images_idx, self.df_target, self.n_colors)\n",
    "        closest_neighbors = df_names.iloc[list(\n",
    "            ranked_neighbors_diff.keys())[0:num_choice]][0]\n",
    "\n",
    "        # find the url of the closest images\n",
    "        image_clustering.open_urls(closest_neighbors, self.csv_path_url)\n",
    "        print(closest_neighbors)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_image_colors(img_path, n_colors):\n",
    "        img = Get_dominant_colors(img_path, (600, 400))\n",
    "        img.get_colors(n_colors)\n",
    "        img_colors = img.ordered_colors\n",
    "        img_colors.extend(list(img.counts.values()))\n",
    "        img_colors = np.array(img_colors).reshape(1, -1)\n",
    "        # Normalize the color map based on their contributions\n",
    "        for i in range(n_colors):\n",
    "            img_colors[0][i*3:(i+1)*3] = img_colors[0][i*3:(i+1)*3] * \\\n",
    "                img_colors[0][n_colors*3+i]/sum(img_colors[0][n_colors*3:])\n",
    "        return img_colors[0][:-n_colors].reshape(1, -1)\n",
    "\n",
    "    @staticmethod\n",
    "    def open_urls(image_names, csv_path_url):\n",
    "        df_url = pd.read_csv(csv_path_url)\n",
    "        for image in image_names:\n",
    "            url = list(df_url.loc[df_url['image_name'] ==\n",
    "                              image[:-4], 'product_url'])[0]\n",
    "            webbrowser.open(url)\n",
    "\n",
    "    @staticmethod\n",
    "    def Lab_color(target_image, neighbor_images, df_images, n_colors):\n",
    "        total_diff = {}\n",
    "        for idx in neighbor_images[0]:\n",
    "            diff = 0\n",
    "            for i in range(n_colors):\n",
    "                target_color = target_image[0][i*3:(i+1)*3]\n",
    "                cur_color = np.array(df_images.iloc[idx, i*3:(i+1)*3])\n",
    "                diff += deltaE_cie76(target_color, cur_color)\n",
    "            total_diff[idx] = diff\n",
    "        total_diff = dict(sorted(total_diff.items(), key=lambda kv: kv[1]))\n",
    "        return total_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T23:42:34.083115Z",
     "start_time": "2019-11-27T23:42:29.385395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236      crushed_velvet_lace_top.jpg\n",
      "303           lace_ruffle_blouse.jpg\n",
      "281    crochet_bell_sleeve_top_1.jpg\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "directory = 'data/venus/women/tops/long_sleeve'\n",
    "img_cluster = image_clustering(directory,\n",
    "                               target_color_map = 'color_map_Lower_cloth.txt',\n",
    "                               target_color_image = 'Lower_cloth_images.txt',\n",
    "                               product_url_file = 'long_sleeve.csv',\n",
    "                               face_file = 'color_map_Face.txt',\n",
    "                               n_clusters = 50,\n",
    "                               weight_face = 0.4,\n",
    "                               n_colors = 3).fit()\n",
    "target_img_path = directory + '/final_images/Cropped_images/Lower_cloth/crushed_velvet_lace_top.jpg'\n",
    "face_img_path = directory + '/final_images/Cropped_images/Face/crushed_velvet_lace_top.jpg'\n",
    "img_cluster.predict(target_img_path, face_img_path, num_choice = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
