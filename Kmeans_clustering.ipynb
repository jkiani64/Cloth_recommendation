{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T00:26:05.480539Z",
     "start_time": "2019-12-04T00:26:02.363196Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from collections import Counter\n",
    "# from skimage.color import rgb2lab, lab2rgb, deltaE_cie76\n",
    "# import os\n",
    "# %matplotlib inline\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# import webbrowser\n",
    "\n",
    "# import pickle\n",
    "# import os\n",
    "# #from clustering_funs import *\n",
    "# # %load_ext autoreload\n",
    "# # %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:35:27.161533Z",
     "start_time": "2019-12-03T00:35:27.127037Z"
    }
   },
   "outputs": [],
   "source": [
    "# class Get_dominant_colors:\n",
    "#     def __init__(self, image_path, size=None):\n",
    "#         '''\n",
    "#         Size should be an Tuple\n",
    "#         '''\n",
    "#         self.image_path = image_path\n",
    "#         self.size = size\n",
    "\n",
    "#     def _get_prepeare_image(self):\n",
    "#         image = cv2.imread(self.image_path)\n",
    "#         self.image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         if not self.size is None:\n",
    "#             self.image_RGB = cv2.resize(\n",
    "#                 self.image_RGB, self.size, interpolation=cv2.INTER_AREA)\n",
    "#         # Convert to Lab format\n",
    "#         self.image_LAB = self._convert_RGB_LAB()\n",
    "#         # Reshape the image\n",
    "#         self.modified_image = self._reshape_image()\n",
    "\n",
    "#     def _convert_RGB_LAB(self):\n",
    "\n",
    "#         return rgb2lab(np.uint8(np.asarray([self.image_RGB])))\n",
    "\n",
    "#     def _reshape_image(self):\n",
    "\n",
    "#         _shape = self.image_LAB.shape[0] * \\\n",
    "#             self.image_LAB.shape[1]*self.image_LAB.shape[2]\n",
    "#         return self.image_LAB.reshape(_shape, 3)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def Lab_2_HEX(color, color_format):\n",
    "#         '''\n",
    "#         This function returns the hex values of the given color.\n",
    "#         The input format should be Lab or RGB\n",
    "#         '''\n",
    "#         assert color_format in [\n",
    "#             'Lab', 'RGB'], 'Color format not in [\"Lab\", \"RGB\"]'\n",
    "#         if color_format == 'Lab':\n",
    "#             color = color.reshape(1, 1, 3)\n",
    "#             color = lab2rgb(color)*255\n",
    "#             color = color.reshape(3,)\n",
    "#         return \"#{:02x}{:02x}{:02x}\".format(int(color[0]), int(color[1]), int(color[2]))\n",
    "\n",
    "#     @staticmethod\n",
    "#     def perform_kmeans(X, n_clusters):\n",
    "#         # Instantiate and fit the Kmeans model\n",
    "#         clf = KMeans(n_clusters=n_clusters, random_state=1985).fit(X)\n",
    "#         return clf\n",
    "\n",
    "#     def get_colors(self, number_of_colors, path_to_save=None):\n",
    "#         # Getting the image\n",
    "#         self._get_prepeare_image()\n",
    "\n",
    "#         # perform kmeans\n",
    "#         self.clf = Get_dominant_colors.perform_kmeans(\n",
    "#             self.modified_image, number_of_colors)\n",
    "\n",
    "#         # sort to ensure correct color percentage\n",
    "#         self.counts = dict(sorted(Counter(self.clf.labels_).items(),\n",
    "#                                   key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "#         # We get ordered colors by iterating through the keys\n",
    "#         self.ordered_colors = list(np.concatenate(\n",
    "#             [self.clf.cluster_centers_[i] for i in self.counts.keys()], axis=0))\n",
    "\n",
    "#         self.hex_colors = [Get_dominant_colors.Lab_2_HEX(self.clf.cluster_centers_[i], 'Lab')\n",
    "#                            for i in self.counts.keys()]\n",
    "\n",
    "#         if not path_to_save is None:\n",
    "            \n",
    "#             color_comp = open(path_to_save, 'a+')\n",
    "            \n",
    "#             temp = self.ordered_colors\n",
    "#             temp.extend(list(self.counts.values()))\n",
    "#             color_comp.writelines([\"%.6f \" % i for i in temp])\n",
    "#             color_comp.writelines(\"\\n\")\n",
    "\n",
    "#     def plot_dominant_colors(self, path_to_save = None):\n",
    "#         plt.figure(figsize=(8, 6))\n",
    "#         plt.pie(self.counts.values(), labels=self.hex_colors,\n",
    "#                 colors=self.hex_colors)\n",
    "#         if path_to_save != None:\n",
    "#             plt.savefig(path_to_save, dpi = 500, bbox_inches='tight')\n",
    "\n",
    "#     def elbow_plot(self, Num_clusters):\n",
    "#         self._get_prepeare_image()\n",
    "#         Sum_of_squared_distances=[]\n",
    "#         K=range(1, Num_clusters + 1)\n",
    "#         for k in K:\n",
    "#             kmeans_mdl=Get_dominant_colors.perform_kmeans(\n",
    "#                 self.modified_image, k)\n",
    "#             Sum_of_squared_distances.append(kmeans_mdl.inertia_)\n",
    "#         plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "#         plt.xlabel('k')\n",
    "#         plt.ylabel('Sum_of_squared_distances')\n",
    "#         plt.title('Elbow Method For Optimal k')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T23:45:44.393701Z",
     "start_time": "2019-12-01T23:45:44.376529Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = 'data/venus/women/tops/long_sleeve/final_images/Cropped_images/Upper_cloth/zip_up_plaid_top.jpg'\n",
    "\n",
    "# img_obj = Get_dominant_colors(path)\n",
    "# img_obj.get_colors(5)\n",
    "# img_obj.plot_dominant_colors('data/color_comp_upper.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T22:11:13.003999Z",
     "start_time": "2019-11-28T22:07:10.855828Z"
    }
   },
   "outputs": [],
   "source": [
    "# dir_overal = 'data/venus/women/tops/cold_shoulder/final_images/Cropped_images'\n",
    "# img_dir = os.path.join(dir_overal, 'Face')\n",
    "# color_map_path = dir_overal + '/color_map_Face.txt'\n",
    "# all_images = os.listdir(img_dir)\n",
    "# try:\n",
    "#     all_images.remove('.DS_Store')\n",
    "# except:\n",
    "#     pass\n",
    "# for img in tqdm(all_images):\n",
    "#     image_path = os.path.join(img_dir, img)\n",
    "#     img_obj = Get_dominant_colors(image_path, (600, 400))\n",
    "#     img_obj.get_colors(3, path_to_save = color_map_path)\n",
    "    \n",
    "# img_file =  dir_overal + '/Face_images.txt'\n",
    "\n",
    "# with open(img_file, 'w') as f:\n",
    "#     for img in all_images:\n",
    "#         f.write('%s\\n' % img)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T22:13:46.391862Z",
     "start_time": "2019-11-28T22:11:13.180557Z"
    }
   },
   "outputs": [],
   "source": [
    "# img_dir = os.path.join(dir_overal, 'Lower_cloth')\n",
    "# color_map_path = dir_overal + '/color_map_Lower_cloth.txt'\n",
    "# # all_images = os.listdir(img_dir)\n",
    "# # all_images.remove('.DS_Store')\n",
    "# for img in tqdm(all_images):\n",
    "#     image_path = os.path.join(img_dir, img)\n",
    "#     img_obj = Get_dominant_colors(image_path, (600, 400))\n",
    "#     img_obj.get_colors(3, path_to_save = color_map_path)\n",
    "    \n",
    "# img_file =  dir_overal + '/Lower_cloth_images.txt'\n",
    "\n",
    "# with open(img_file, 'w') as f:\n",
    "#     for img in all_images:\n",
    "#         f.write('%s\\n' % img)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T22:16:50.370550Z",
     "start_time": "2019-11-28T22:13:46.596294Z"
    }
   },
   "outputs": [],
   "source": [
    "# img_dir = os.path.join(dir_overal, 'Upper_cloth')\n",
    "# color_map_path = dir_overal + '/color_map_Upper_cloth.txt'\n",
    "# # all_images = os.listdir(img_dir)\n",
    "# # all_images.remove('.DS_Store')\n",
    "# for img in tqdm(all_images):\n",
    "#     image_path = os.path.join(img_dir, img)\n",
    "#     img_obj = Get_dominant_colors(image_path, (600, 400))\n",
    "#     img_obj.get_colors(3, path_to_save = color_map_path)\n",
    "    \n",
    "# img_file =  dir_overal + '/Upper_cloth_images.txt'\n",
    "\n",
    "# with open(img_file, 'w') as f:\n",
    "#     for img in all_images:\n",
    "#         f.write('%s\\n' % img)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:35:49.614010Z",
     "start_time": "2019-12-03T00:35:49.546355Z"
    }
   },
   "outputs": [],
   "source": [
    "# class image_clustering:\n",
    "#     \"\"\"\n",
    "#     It uses Kmeans clustering to group all\n",
    "#     the images with the same color composition\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     n_clusters : int, optional, default: 50\n",
    "#         The number of clusters to form as well as the number of\n",
    "#         centroids to generate.\n",
    "#     directory : str\n",
    "#         the direcotory of all files\n",
    "#     product_url_file : str\n",
    "#         The name of csv file including the URL of all images\n",
    "#     n_colors : int\n",
    "#         The number of dominant colors default is 3\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     cluster_centers_ : array, [n_clusters, n_features]\n",
    "#         Coordinates of cluster centers. If the algorithm stops before fully\n",
    "#         converging (see ``tol`` and ``max_iter``), these will not be\n",
    "#         consistent with ``labels_``.\n",
    "#     labels_ :\n",
    "#         Labels of each point\n",
    "#     inertia_ : float\n",
    "#         Sum of squared distances of samples to their closest cluster center.\n",
    "#     n_iter_ : int\n",
    "#         Number of iterations run.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, directory, target_color_map, target_color_image, product_url_file,\n",
    "#                  face_file=None, n_clusters=50, weight_face=0, n_colors=3):\n",
    "#         self.n_colors = n_colors\n",
    "#         assert weight_face >= 0 and weight_face <= 1, print(\n",
    "#             'The weight assigned to the face should be between 0 and 1')\n",
    "#         self.weight_face = weight_face\n",
    "#         self.n_clusters = n_clusters\n",
    "#         self.target_path = os.path.join(\n",
    "#             directory, 'final_images/Cropped_images/' + target_color_map)\n",
    "        \n",
    "#         self.target_image_path = os.path.join(\n",
    "#             directory, 'final_images/Cropped_images/' + target_color_image)\n",
    "        \n",
    "#         if face_file == None:\n",
    "#             self.face_path = None\n",
    "#         else:\n",
    "#             self.face_path = os.path.join(\n",
    "#                 directory, 'final_images/Cropped_images/' + face_file)\n",
    "\n",
    "#         self.csv_path_url = os.path.join(directory, product_url_file)\n",
    "        \n",
    "        \n",
    "#         # Read the name of all lower clothes images\n",
    "#         self.df_names = pd.read_csv(self.target_image_path, header=None)\n",
    "\n",
    "#     def fit(self):\n",
    "#         \"\"\"\n",
    "#         Compute k-means clustering.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
    "#             Training instances to cluster. It must be noted that the data\n",
    "#             will be converted to C ordering, which will cause a memory\n",
    "#             copy if the given data is not C-contiguous.\n",
    "#         \"\"\"\n",
    "#         self.df_target = image_clustering.read_txt_files(\n",
    "#             self.target_path)\n",
    "#         if not self.face_path is None:\n",
    "#             self.df_target = (1-self.weight_face) * self.df_target +\\\n",
    "#                 self.weight_face * \\\n",
    "#                 image_clustering.read_txt_files(self.face_path)\n",
    "\n",
    "#         # fit the model\n",
    "#         self.mdl = image_clustering.fit_kmeans(\n",
    "#             self.df_target[list(range(9))], self.n_clusters)\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_txt_files(file_path):\n",
    "#         df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "#         freq_cols = [9, 10, 11]\n",
    "#         df[12] = df[freq_cols].sum(axis=1)\n",
    "#         for i in freq_cols:\n",
    "#             df[i] /= df[12]\n",
    "#         color_cols = list(range(0, 9))\n",
    "#         for i in color_cols:\n",
    "#             df[i] *= df[i // 3 + 9]\n",
    "#         try:\n",
    "#             df.drop(columns=[12], axis=1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         return df\n",
    "\n",
    "#     @staticmethod\n",
    "#     def fit_kmeans(X, k):\n",
    "#         mdl = KMeans(n_clusters=k,\n",
    "#                      random_state=1985)\n",
    "#         mdl.fit(X)\n",
    "#         return mdl\n",
    "\n",
    "#     def histohram_plot_cluster(self, path_save_hist=None):\n",
    "#         if not hasattr(img_cluster, 'mdl'):\n",
    "#             raise ValueError('A model should be fitted first!')\n",
    "#         plt.hist(self.mdl.labels_, bins=self.n_clusters)\n",
    "#         plt.title('Histogram of Color Composition')\n",
    "#         plt.xlabel('Cloth group label')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         if not path_save_hist is None:\n",
    "#             plt.savefig(path_save_hist, dpi = 500, bbox_inches='tight')\n",
    "\n",
    "#     def predict(self, image_path_test, face_path_test=None, num_choice=5):\n",
    "#         \"\"\"\n",
    "#         Predict the closest image to the test image\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         image_path_test: a path of the test image\n",
    "#         num_choice: the number of desired choices\n",
    "#         Returns\n",
    "#         -------\n",
    "#         labels: array, shape[n_samples, ]\n",
    "#             Index of the cluster each sample belongs to.\n",
    "#         \"\"\"\n",
    "#         img_colors = image_clustering.normalize_image_colors(image_path_test, self.n_colors)\n",
    "#         if not self.face_path is None:\n",
    "#             temp_face = image_clustering.normalize_image_colors(\n",
    "#                 face_path_test, self.n_colors)\n",
    "#             img_colors = temp_face * self.weight_face + \\\n",
    "#                 (1 - self.weight_face) * img_colors\n",
    "\n",
    "#         # Predict cluster number for the test image\n",
    "#         test_label = self.mdl.predict(img_colors)\n",
    "\n",
    "#         # Finding the index of neighbors in the same cluster\n",
    "#         neighbor_images_idx = np.where(\n",
    "#             img_cluster.mdl.labels_ == test_label[0])\n",
    "\n",
    "#         # Find the closest images to the target image\n",
    "#         ranked_neighbors_diff = image_clustering.Lab_color(\n",
    "#             img_colors, neighbor_images_idx, self.df_target, self.n_colors)\n",
    "#         closest_neighbors = self.df_names.iloc[list(\n",
    "#             ranked_neighbors_diff.keys())[0:num_choice]][0]\n",
    "\n",
    "#         # find the url of the closest images\n",
    "#         image_clustering.open_urls(closest_neighbors, self.csv_path_url)\n",
    "#         print(closest_neighbors)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def normalize_image_colors(img_path, n_colors):\n",
    "#         img = Get_dominant_colors(img_path, (600, 400))\n",
    "#         img.get_colors(n_colors)\n",
    "#         img_colors = img.ordered_colors\n",
    "#         img_colors.extend(list(img.counts.values()))\n",
    "#         img_colors = np.array(img_colors).reshape(1, -1)\n",
    "#         # Normalize the color map based on their contributions\n",
    "#         for i in range(n_colors):\n",
    "#             img_colors[0][i*3:(i+1)*3] = img_colors[0][i*3:(i+1)*3] * \\\n",
    "#                 img_colors[0][n_colors*3+i]/sum(img_colors[0][n_colors*3:])\n",
    "#         return img_colors[0][:-n_colors].reshape(1, -1)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def open_urls(image_names, csv_path_url):\n",
    "#         df_url = pd.read_csv(csv_path_url)\n",
    "#         for image in image_names:\n",
    "#             url = list(df_url.loc[df_url['image_name'] ==\n",
    "#                               image[:-4], 'product_url'])[0]\n",
    "#             webbrowser.open(url)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def Lab_color(target_image, neighbor_images, df_images, n_colors):\n",
    "#         total_diff = {}\n",
    "#         for idx in neighbor_images[0]:\n",
    "#             diff = 0\n",
    "#             for i in range(n_colors):\n",
    "#                 target_color = target_image[0][i*3:(i+1)*3]\n",
    "#                 cur_color = np.array(df_images.iloc[idx, i*3:(i+1)*3])\n",
    "#                 diff += deltaE_cie76(target_color, cur_color)\n",
    "#             total_diff[idx] = diff\n",
    "#         total_diff = dict(sorted(total_diff.items(), key=lambda kv: kv[1]))\n",
    "#         return total_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T17:14:14.393368Z",
     "start_time": "2019-12-03T17:14:14.388205Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory = 'data/venus/women/tops/long_sleeve'\n",
    "# img_cluster = image_clustering(directory,\n",
    "#                                target_color_map = 'color_map_Lower_cloth.txt',\n",
    "#                                target_color_image = 'Lower_cloth_images.txt',\n",
    "#                                product_url_file = 'long_sleeve.csv',\n",
    "#                                face_file = 'color_map_Face.txt',\n",
    "#                                n_clusters = 50,\n",
    "#                                weight_face = 0.4,\n",
    "#                                n_colors = 3).fit()\n",
    "\n",
    "\n",
    "# #img_cluster.histohram_plot_cluster(path_save_hist='data/hist_color.jpg')\n",
    "# target_img_path = directory + '/final_images/Cropped_images/Lower_cloth/crushed_velvet_lace_top.jpg'\n",
    "# face_img_path = directory + '/final_images/Cropped_images/Face/crushed_velvet_lace_top.jpg'\n",
    "# img_cluster.predict(target_img_path, face_img_path, num_choice = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:38:48.634021Z",
     "start_time": "2019-12-03T00:38:48.628499Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:58:35.672778Z",
     "start_time": "2019-12-03T00:58:35.657572Z"
    }
   },
   "outputs": [],
   "source": [
    "#pickle.dump(img_cluster, open('img_cluster.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T16:00:34.191306Z",
     "start_time": "2019-12-03T16:00:34.099340Z"
    }
   },
   "outputs": [],
   "source": [
    "# # # Loading model to compare the results\n",
    "# pickle.dump(img_cluster, open('img_cluster.pkl','wb'))\n",
    "# model = pickle.load(open('img_cluster.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T16:16:10.557644Z",
     "start_time": "2019-12-03T16:16:06.580893Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory = 'data/venus/women/tops/long_sleeve'\n",
    "# #img_cluster.histohram_plot_cluster(path_save_hist='data/hist_color.jpg')\n",
    "# target_img_path = directory + '/final_images/Cropped_images/Lower_cloth/crushed_velvet_lace_top.jpg'\n",
    "# face_img_path = directory + '/final_images/Cropped_images/Face/crushed_velvet_lace_top.jpg'\n",
    "# model.predict(target_img_path, face_img_path, num_choice = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T21:37:05.674267Z",
     "start_time": "2019-12-04T21:37:05.630783Z"
    }
   },
   "outputs": [],
   "source": [
    "#directory = '~/For_prac/Deployment-Deep-Learning-Model-master/uploads/'\n",
    "#img_cluster.histohram_plot_cluster(path_save_hist='data/hist_color.jpg')\n",
    "#target_img_path = '/Users/jalalkiani/For_prac/Deployment-Deep-Learning-Model-master/uploads/crushed_velvet_lace_top.jpg'\n",
    "#model.predict(target_img_path, target_img_path, num_choice = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T16:23:53.398252Z",
     "start_time": "2019-12-03T16:23:53.392716Z"
    }
   },
   "outputs": [],
   "source": [
    "# target_img_path = '/Users/jalalkiani/For_prac/Deployment-Deep-Learning-Model-master/uploads/crushed_velvet_lace_top.jpg'\n",
    "\n",
    "# #Get_dominant_colors(target_img_path,(600, 400)).get_colors(3)\n",
    "# #!open target_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:51:02.587315Z",
     "start_time": "2019-12-03T00:51:02.581666Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory = 'data/venus/women/tops/long_sleeve'\n",
    "# img_cluster = image_clustering(directory,\n",
    "#                                target_color_map = 'color_map_Lower_cloth.txt',\n",
    "#                                target_color_image = 'Lower_cloth_images.txt',\n",
    "#                                product_url_file = 'long_sleeve.csv',\n",
    "#                                face_file = 'color_map_Face.txt',\n",
    "#                                n_clusters = 50,\n",
    "#                                weight_face = 0,\n",
    "#                                n_colors = 3).fit()\n",
    "\n",
    "\n",
    "# #img_cluster.histohram_plot_cluster(path_save_hist='data/hist_color_Upper.jpg')\n",
    "# img_name = 'floral_off_the_shoulder_top.jpg'\n",
    "# target_img_path = directory + '/final_images/Cropped_images/Lower_cloth/' +  img_name\n",
    "# face_img_path = directory + '/final_images/Cropped_images/Face/' + img_name\n",
    "# img_cluster.predict(target_img_path, face_img_path, num_choice = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:50:54.357613Z",
     "start_time": "2019-12-03T00:50:54.351259Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory = 'data/venus/women/tops/long_sleeve'\n",
    "# img_cluster = image_clustering(directory,\n",
    "#                                target_color_map = 'color_map_Upper_cloth.txt',\n",
    "#                                target_color_image = 'Upper_cloth_images.txt',\n",
    "#                                product_url_file = 'long_sleeve.csv',\n",
    "#                                face_file = 'color_map_Face.txt',\n",
    "#                                n_clusters = 50,\n",
    "#                                weight_face = 0,\n",
    "#                                n_colors = 3).fit()\n",
    "\n",
    "\n",
    "# #img_cluster.histohram_plot_cluster(path_save_hist='data/hist_color_Upper.jpg')\n",
    "# img_name = 'embroidered_bell_sleeve_top.jpg'\n",
    "# target_img_path = directory + '/final_images/Cropped_images/Upper_cloth/' +  img_name\n",
    "# face_img_path = directory + '/final_images/Cropped_images/Face/' + img_name\n",
    "# img_cluster.predict(target_img_path, face_img_path, num_choice = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T00:50:54.878199Z",
     "start_time": "2019-12-03T00:50:54.871290Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory = 'data/venus/women/tops/long_sleeve/final_images/Cropped_images/Upper_cloth/'\n",
    "# plt.figure(figsize = (12, 8))\n",
    "# my_list = img_cluster.df_names.loc[np.where(img_cluster.mdl.labels_ == 8)][0]\n",
    "# for idx, img in enumerate(my_list):\n",
    "#     path = directory + img\n",
    "#     img = cv2.imread(path)\n",
    "#     plt.subplot(1,len(my_list), idx+1)\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T00:26:14.264663Z",
     "start_time": "2019-12-04T00:26:14.205499Z"
    }
   },
   "outputs": [],
   "source": [
    "# class image_clustering:\n",
    "#     \"\"\"\n",
    "#     It uses Kmeans clustering to group all\n",
    "#     the images with the same color composition\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     n_clusters : int, optional, default: 50\n",
    "#         The number of clusters to form as well as the number of\n",
    "#         centroids to generate.\n",
    "#     directory : str\n",
    "#         the direcotory of all files\n",
    "#     product_url_file : str\n",
    "#         The name of csv file including the URL of all images\n",
    "#     n_colors : int\n",
    "#         The number of dominant colors default is 3\n",
    "\n",
    "#     Attributes\n",
    "#     ----------\n",
    "#     cluster_centers_ : array, [n_clusters, n_features]\n",
    "#         Coordinates of cluster centers. If the algorithm stops before fully\n",
    "#         converging (see ``tol`` and ``max_iter``), these will not be\n",
    "#         consistent with ``labels_``.\n",
    "#     labels_ :\n",
    "#         Labels of each point\n",
    "#     inertia_ : float\n",
    "#         Sum of squared distances of samples to their closest cluster center.\n",
    "#     n_iter_ : int\n",
    "#         Number of iterations run.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, target_color_map, target_color_image, product_url_file,\n",
    "#                  face_file=None, n_clusters=50, weight_face=0, n_colors=3):\n",
    "#         self.n_colors = n_colors\n",
    "#         assert weight_face >= 0 and weight_face <= 1, print(\n",
    "#             'The weight assigned to the face should be between 0 and 1')\n",
    "#         self.weight_face = weight_face\n",
    "#         self.n_clusters = n_clusters\n",
    "#         self.target_path = os.path.join(\n",
    "#             './static/Cropped_images/', target_color_map)\n",
    "\n",
    "#         self.target_image_path = os.path.join(\n",
    "#             './static/Cropped_images/', target_color_image)\n",
    "\n",
    "#         if face_file == None:\n",
    "#             self.face_path = None\n",
    "#         else:\n",
    "#             self.face_path = os.path.join(\n",
    "#                 './static/Cropped_images/', face_file)\n",
    "\n",
    "#         self.csv_path_url = os.path.join(\n",
    "#             './static/Cropped_images/', product_url_file)\n",
    "\n",
    "#         # Read the name of all lower clothes images\n",
    "#         self.df_names = pd.read_csv(self.target_image_path, header=None)\n",
    "\n",
    "#     def fit(self):\n",
    "#         \"\"\"\n",
    "#         Compute k-means clustering.\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
    "#             Training instances to cluster. It must be noted that the data\n",
    "#             will be converted to C ordering, which will cause a memory\n",
    "#             copy if the given data is not C-contiguous.\n",
    "#         \"\"\"\n",
    "#         self.df_target = image_clustering.read_txt_files(\n",
    "#             self.target_path)\n",
    "#         if not self.face_path is None:\n",
    "#             self.df_target = (1-self.weight_face) * self.df_target +\\\n",
    "#                 self.weight_face * \\\n",
    "#                 image_clustering.read_txt_files(self.face_path)\n",
    "\n",
    "#         # fit the model\n",
    "#         self.mdl = image_clustering.fit_kmeans(\n",
    "#             self.df_target[list(range(9))], self.n_clusters)\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     @staticmethod\n",
    "#     def read_txt_files(file_path):\n",
    "#         df = pd.read_csv(file_path, sep=\" \", header=None)\n",
    "#         freq_cols = [9, 10, 11]\n",
    "#         df[12] = df[freq_cols].sum(axis=1)\n",
    "#         for i in freq_cols:\n",
    "#             df[i] /= df[12]\n",
    "#         color_cols = list(range(0, 9))\n",
    "#         for i in color_cols:\n",
    "#             df[i] *= df[i // 3 + 9]\n",
    "#         try:\n",
    "#             df.drop(columns=[12], axis=1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         return df\n",
    "\n",
    "#     @staticmethod\n",
    "#     def fit_kmeans(X, k):\n",
    "#         mdl = KMeans(n_clusters=k,\n",
    "#                      random_state=1985)\n",
    "#         mdl.fit(X)\n",
    "#         return mdl\n",
    "\n",
    "#     def histohram_plot_cluster(self, path_save_hist=None):\n",
    "#         if not hasattr(img_cluster, 'mdl'):\n",
    "#             raise ValueError('A model should be fitted first!')\n",
    "#         plt.hist(self.mdl.labels_, bins=self.n_clusters)\n",
    "#         plt.title('Histogram of Color Composition')\n",
    "#         plt.xlabel('Cloth group label')\n",
    "#         plt.ylabel('Frequency')\n",
    "#         if not path_save_hist is None:\n",
    "#             plt.savefig(path_save_hist, dpi=500, bbox_inches='tight')\n",
    "\n",
    "#     def predict(self, image_path_test, face_path_test=None, num_choice=5, open_url=False):\n",
    "#         \"\"\"\n",
    "#         Predict the closest image to the test image\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         image_path_test: a path of the test image\n",
    "#         num_choice: the number of desired choices\n",
    "#         Returns\n",
    "#         -------\n",
    "#         labels: array, shape[n_samples, ]\n",
    "#             Index of the cluster each sample belongs to.\n",
    "#         \"\"\"\n",
    "#         image_path_test = os.path.join(\n",
    "#             './static/Cropped_images/Lower_cloth/', image_path_test)\n",
    "#         img_colors = image_clustering.normalize_image_colors(\n",
    "#             image_path_test, self.n_colors)\n",
    "\n",
    "#         if not self.face_path is None:\n",
    "#             face_path_test = os.path.join(\n",
    "#             './static/Cropped_images/Face/', face_path_test)\n",
    "#             temp_face = image_clustering.normalize_image_colors(\n",
    "#                 face_path_test, self.n_colors)\n",
    "#             img_colors = temp_face * self.weight_face + \\\n",
    "#                 (1 - self.weight_face) * img_colors\n",
    "\n",
    "#         # Predict cluster number for the test image\n",
    "#         test_label = self.mdl.predict(img_colors)\n",
    "\n",
    "#         # Finding the index of neighbors in the same cluster\n",
    "#         neighbor_images_idx = np.where(\n",
    "#             self.mdl.labels_ == test_label[0])\n",
    "\n",
    "#         # Find the closest images to the target image\n",
    "#         ranked_neighbors_diff = image_clustering.Lab_color(\n",
    "#             img_colors, neighbor_images_idx, self.df_target, self.n_colors)\n",
    "#         closest_neighbors = self.df_names.iloc[list(\n",
    "#             ranked_neighbors_diff.keys())[0:num_choice]][0]\n",
    "\n",
    "#         # find the url of the closest images\n",
    "#         recommended_urls = image_clustering.open_urls(\n",
    "#             closest_neighbors, self.csv_path_url, open_url)\n",
    "#         return [list(closest_neighbors), recommended_urls]\n",
    "\n",
    "#     @staticmethod\n",
    "#     def normalize_image_colors(img_path, n_colors):\n",
    "#         #img = Get_dominant_colors(img_path, (600, 400))\n",
    "#         # img.get_colors(n_colors)\n",
    "#         #img_colors = img.ordered_colors\n",
    "\n",
    "#         image = cv2.imread(img_path)\n",
    "#         image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image_RGB = cv2.resize(image_RGB, (600, 400),\n",
    "#                                interpolation=cv2.INTER_AREA)\n",
    "#         # Convert to Lab format\n",
    "#         image_LAB = rgb2lab(np.uint8(np.asarray([image_RGB])))\n",
    "#         # Reshape the image\n",
    "#         _shape = image_LAB.shape[0] * image_LAB.shape[1]*image_LAB.shape[2]\n",
    "#         modified_image = image_LAB.reshape(_shape, 3)\n",
    "\n",
    "#         # perform kmeans\n",
    "#         clf = KMeans(n_clusters=n_colors,\n",
    "#                      random_state=1985).fit(modified_image)\n",
    "\n",
    "#         # sort to ensure correct color percentage\n",
    "#         _counts = dict(sorted(Counter(clf.labels_).items(),\n",
    "#                               key=lambda kv: kv[1], reverse=True))\n",
    "\n",
    "#         # We get ordered colors by iterating through the keys\n",
    "#         img_colors = list(np.concatenate(\n",
    "#             [clf.cluster_centers_[i] for i in _counts.keys()], axis=0))\n",
    "\n",
    "#         img_colors.extend(list(_counts.values()))\n",
    "#         img_colors = np.array(img_colors).reshape(1, -1)\n",
    "#         # Normalize the color map based on their contributions\n",
    "#         for i in range(n_colors):\n",
    "#             img_colors[0][i*3:(i+1)*3] = img_colors[0][i*3:(i+1)*3] * \\\n",
    "#                 img_colors[0][n_colors*3+i]/sum(img_colors[0][n_colors*3:])\n",
    "#         return img_colors[0][:-n_colors].reshape(1, -1)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def open_urls(image_names, csv_path_url, open_url=False):\n",
    "#         df_url = pd.read_csv(csv_path_url)\n",
    "#         urls = []\n",
    "#         for image in image_names:\n",
    "#             url = list(df_url.loc[df_url['image_name'] ==\n",
    "#                                   image[:-4], 'product_url'])[0]\n",
    "#             urls.append(url)\n",
    "#             if open_url:\n",
    "#                 webbrowser.open(url)\n",
    "#         return urls\n",
    "\n",
    "#     @staticmethod\n",
    "#     def Lab_color(target_image, neighbor_images, df_images, n_colors):\n",
    "#         total_diff = {}\n",
    "#         for idx in neighbor_images[0]:\n",
    "#             diff = 0\n",
    "#             for i in range(n_colors):\n",
    "#                 target_color = target_image[0][i*3:(i+1)*3]\n",
    "#                 cur_color = np.array(df_images.iloc[idx, i*3:(i+1)*3])\n",
    "#                 diff += deltaE_cie76(target_color, cur_color)\n",
    "#             total_diff[idx] = diff\n",
    "#         total_diff = dict(sorted(total_diff.items(), key=lambda kv: kv[1]))\n",
    "#         return total_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T21:46:01.874448Z",
     "start_time": "2019-12-04T21:45:57.877890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['strappy_detail_top_1.jpg',\n",
       "  'lace_detail_tie_front_top.jpg',\n",
       "  'strappy_back_detail_top.jpg'],\n",
       " ['https://www.venus.com/viewproduct.aspx?BRANCH=7~63~2052~&ProductDisplayID=63796',\n",
       "  'https://www.venus.com/viewproduct.aspx?BRANCH=7~63~2052~&ProductDisplayID=60589',\n",
       "  'https://www.venus.com/viewproduct.aspx?BRANCH=7~63~2052~&ProductDisplayID=62602']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clustering_funs import *\n",
    "import pickle\n",
    "\n",
    "img_cluster = image_clustering(target_color_map = 'color_map_Lower_cloth.txt',\n",
    "                               target_color_image = 'Lower_cloth_images.txt',\n",
    "                               product_url_file = 'long_sleeve.csv',\n",
    "                               face_file = None,\n",
    "                               n_clusters = 50,\n",
    "                               weight_face = 0,\n",
    "                               n_colors = 3).fit()\n",
    "\n",
    "\n",
    "target_img_path = 'strappy_detail_top_1.jpg'\n",
    "face_img_path =  'strappy_detail_top_1.jpg'\n",
    "recommended_images = img_cluster.predict(target_img_path, face_img_path, num_choice = 3, open_url = False)\n",
    "\n",
    "# # Loading model to compare the results\n",
    "pickle.dump(img_cluster, open('img_cluster.pkl','wb'))\n",
    "# model = pickle.load(open('img_cluster.pkl','rb'))\n",
    "recommended_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T21:41:03.181841Z",
     "start_time": "2019-12-04T21:41:03.176319Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# model = pickle.load(open('img_cluster.pkl','rb'))\n",
    "# target_img_path = 'strappy_detail_top_1.jpg'\n",
    "# # face_img_path = directory + '/final_images/Cropped_images/Face/strappy_detail_top_1.jpg'\n",
    "# model.predict(target_img_path, None, num_choice = 3, open_url = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T16:07:30.544440Z",
     "start_time": "2019-12-04T16:07:30.521903Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
